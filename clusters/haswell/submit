#!/usr/bin/env python
# encoding: utf-8

"""This script submits Q-Chem jobs to the queue

Authors: Daniel   Lambrecht (original)
         Benjamin  Albrecht (rewritten)
         Eric      Berquist (rewritten for SLURM)
"""

from __future__ import print_function

import sys

try:
    import os
    import argparse
    import shlex
    from uuid import uuid4
    import subprocess as sp
except ImportError:
    if sys.version_info < (2, 7):
        raise Exception("Python >= 2.7 required")



def get_arguments(args=None):
    """Get arguments from user"""

    # Determine default Q-Chem version
    # We first try $QC environment variable, if that is not defined,
    # we assume we are on H2P and we pick the latest version of the
    # Q-Chem trunk
    def_path = os.environ.get("QC")
    # if not def_path:
    #     qchem_dir = "/ihome/dlambrecht/software/qchem"
    #     all_subdirs = [qchem_dir + "/" + d
    #                    for d in os.listdir(qchem_dir)
    #                    if d not in ('qcaux', 'qcref', 'qc_ext_libs')]
    #     latest_subdir = max(all_subdirs, key=os.path.getmtime)
    #     def_path = latest_subdir # default version

    # Argparse parsing
    parser = argparse.ArgumentParser(prog="submit",
                                     usage="%(prog)s job [options] ",
                                     description=""" %(prog)s is a script that auto-generates a SLURM
                                     file and submits a job""",
                                     formatter_class=argparse.ArgumentDefaultsHelpFormatter)

    # pylint: disable=C0326
    parser.add_argument('job',         type=str,  nargs='+', help='Input File')
    parser.add_argument('--ppn',       type=int,  default=1, help='Number of processors per node')
    parser.add_argument('--nodes',     type=int,  default=1, help='Number of nodes')
    # parser.add_argument('--mem',       type=int,  default=-1, help='gb of memory')
    # parser.add_argument('--disk',      type=int,  default=-1, help='gb of scratch disk space')
    # see https://crc.pitt.edu/documentation/h2p/ for more information
    parser.add_argument('--cluster',   type=str,  default='smp', help='Queue (cluster) to submit to')
    parser.add_argument('--partition', type=str,  default='smp', help='Queue (hardware) within cluster')
    parser.add_argument('--walltime',  type=str,  default='1:00:00', help='Walltime in HH:MM:SS format')
    parser.add_argument('--path',      type=str,  default=def_path, help='Path to program')
    parser.add_argument('--saveslurm', action='store_true', help='Save submission script (SLURM file) when set')
    parser.add_argument('--save',      action='store_true', help='Save scratch directory when set')
    parser.add_argument('--dry',       action='store_true', help='Do not run sbatch on SLURM file when True')
    parser.add_argument('--email',     type=str,  default='off', help='Email address for job start/finish notifications, set to "off" to turn off')
    parser.add_argument('--jobname',   type=str,  default='off', help='jobname to display in queue')
    # parser.add_argument('--qcrc',      type=str,  default='off', help='qcrc path, defaults to qcrc instead of checking for Q-Chem modules, \'auto\' will find the last modified qcrc')

    opts = parser.parse_args(args)
    print(opts)

    return opts


def writeslurm(opts, job):
    """Write submission script
    """

    job_name, __ = os.path.splitext(job)
    # Create unique ID for job
    JOB_ID = uuid4().hex 
    RUN = "." + job_name + "." + JOB_ID + ".slurm"

    print("run script = ", RUN)

    fileh = open(RUN, "w")

    fileh.write("#!/bin/bash\n")
    fileh.write("\n")

    if opts.jobname == 'off':
        job_dir = os.path.basename(os.path.dirname(os.path.realpath(job)))
        fileh.write("#SBATCH --job-name=" + job_dir + "/" + job_name + "\n")
    else:
        fileh.write("#SBATCH --job-name=" + opts.jobname + "\n")
    fileh.write("#SBATCH --output=" + job_name + ".slurmout\n")

    fileh.write("#SBATCH --nodes=" + str(opts.nodes) + "\n")
    fileh.write("#SBATCH --ntasks-per-node=" + str(opts.ppn) + "\n")
    fileh.write("#SBATCH --time=" + opts.walltime + "\n")

    # Memory
    # TODO
    # if opts.mem > 0:
    #     fileh.write("#PBS -l mem=" + str(opts.mem) + "gb\n")
    #     fileh.write("#PBS -l pmem=" + str(opts.mem) + "gb\n")
    # if opts.disk > 0:
    #     fileh.write("#PBS -l ddisk=" + str(opts.disk) + "gb\n")

    fileh.write("#SBATCH --cluster=" + opts.cluster + "\n")
    fileh.write("#SBATCH --partition=" + opts.partition + "\n")

    # Priority
    # TODO

    # Error Logging
    # TODO
    # fileh.write("#PBS -j oe\n")

    # Email Logging
    # TODO
    # if not opts.email == "off":
    #     fileh.write("#PBS -m abe\n")
    #     fileh.write("#PBS -M " + opts.email + "\n")
    fileh.write("\n")

    fileh.write("module purge\n")
    fileh.write("module load intel/2017.3.196\n")

    # Modules / qcrc - module manually updated
    # This will load lexicograpically greatest version
    module = "qchem/dlambrecht"
    moduleavail = "modulecmd bash avail " + module
    status = sp.check_output(shlex.split(moduleavail), stderr=sp.STDOUT).decode()

    opts.qcrc = '/ihome/dlambrecht/erb74/opt/apps/qchem/haswell/5.0.2-r26631-20171216-i2017.1.132/qcrc_erb74'
    if module in status and opts.qcrc == 'off':
        fileh.write("module load " + module + "\n")
    elif opts.qcrc == 'auto' or opts.qcrc == 'off':
        qcrc = os.path.join(opts.path, 'qcrc')
        fileh.write("source " + qcrc + "\n")
    else:
        qcrc = opts.qcrc
        if os.path.isfile(qcrc):
            fileh.write("source " + qcrc + "\n")
        else:
            print(qcrc, 'does not exist')
            raise FileNotFoundError

    fileh.write("\n")

    fileh.write("cd ${SLURM_SUBMIT_DIR}\n")
    fileh.write("cp ${SLURM_SUBMIT_DIR}/"+job+" ${SLURM_SCRATCH}\n")
    fileh.write("cd ${SLURM_SCRATCH}\n")
    fileh.write("\n")

    if opts.save:
        fileh.write("run_on_exit() {\n")
        fileh.write("    set -v\n")
        fileh.write("    rm ${SLURM_SCRATCH}/pathtable\n")
        fileh.write("    cp -v -R ${SLURM_SCRATCH}/* $SLURM_SUBMIT_DIR\n")
        fileh.write("}\n")
        fileh.write("\n")

        fileh.write("trap run_on_exit EXIT\n")
        fileh.write("\n")


    parallel_string = ""
    if int(opts.nodes) > 1:
        # total_cores = str(int(opts.nodes) * int(opts.ppn))
        parallel_string = "-np " + str(opts.nodes) + " -nt " + str(opts.ppn)
    elif int(opts.ppn) > 1:
        parallel_string = "-nt ${PPN} "

    save_string = ""
    if opts.save:
        save_string = " -save "

    fileh.write("\n")
    fileh.write("$(which qchem)" + parallel_string + save_string + " " + job + " ${SLURM_SUBMIT_DIR}/" + job_name + ".out " + job_name + "." + JOB_ID + "\n")
    fileh.write("chmod 640 ${SLURM_SUBMIT_DIR}/" + job_name + ".out\n")
    fileh.write("\n")

    if opts.save:
        fileh.write("cp -r ${SLURM_SCRATCH}/* ${SLURM_SUBMIT_DIR}/\n")

    if not opts.saveslurm:
        fileh.write("rm ${SLURM_SUBMIT_DIR}/" + RUN + "\n")

    fileh.close()

    return RUN


def submit(RUN):
    """ Wrapper function for sbatch / Writes QUID file if aggressively submitting

    :RUN: pbs file to run
    """

    bashCommand = 'sbatch ' + RUN
    status = sp.check_output(shlex.split(bashCommand)).decode()

    return status


def main():

    opts = get_arguments()

    for job in opts.job:
        print(job)
        #job_name = os.path.splitext(job)[0]
        job_name = os.path.basename(job)
        print("job name = ", job_name)

        RUN = writeslurm(opts, job)

        if not opts.dry:
            submit(RUN)


if __name__ == '__main__':
    main()
